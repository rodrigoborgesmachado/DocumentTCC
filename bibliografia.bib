@inproceedings{xiao2018patching,
author = {Xiao, Chaowei and Sarabi, Armin and Liu, Yang and Li, Bo and Liu, Mingyan and Dumitras, Tudor},
booktitle = {27th USENIX Security Symposium (USENIX Security 18)},
pages = {903--918},
title = {{From patching delays to infection symptoms: using risk profiles for an early discovery of vulnerabilities exploited in the wild}},
year = {2018}
}
@article{Peotta2006,
abstract = {RESUMO Um tema que vem sendo muito discutido {\'{e}} a governan{\c{c}}a em TI (Tecnologia da informa{\c{c}}{\~{a}}o), no entanto existem muitos m{\'{e}}todos e t{\'{e}}cnicas de gest{\~{a}}o que podem ser adotadas para se implement{\'{a}}-la. Um bom ponto de partida seria elaborar um plano para an{\'{a}}lise de risco em TI, controlando e conhecendo a infra-estrutura, agilizando a tomada de decis{\~{a}}o visando reduzir ou mitigar o risco. Neste artigo ser{\'{a}} descrito uma metodologia para efetuar uma an{\'{a}}lise de risco eficiente. Palavras-Chave: Gest{\~{a}}o de risco, Seguran{\c{c}}a da informa{\c{c}}{\~{a}}o, Governan{\c{c}}a, Compliance.},
author = {Peotta, Laerte and Gondim, Paulo},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/1049{\_}risco.pdf:pdf},
journal = {SEGeT – Simp{\'{o}}sio de Excel{\^{e}}ncia em Gest{\~{a}}o e Tecnologia},
pages = {1--12},
title = {{An{\'{a}}lise de Risco em Ambientes Corporativos na {\'{A}}rea de Tecnologia da Informa{\c{c}}{\~{a}}o}},
url = {http://ww.aedb.br/seget/artigos07/1049{\_}risco.pdf},
year = {2006}
}
@misc{OSVDB2002,
author = {OSVDB},
title = {{OSVDB | Everything is Vulnerable}},
url = {https://blog.osvdb.org/},
urldate = {2018-12-12},
year = {2002}
}
@misc{CERT1991,
author = {CERT},
title = {{US-CERT | United States Computer Emergency Readiness Team}},
url = {https://www.us-cert.gov/},
urldate = {2018-12-12},
year = {1991}
}
@misc{Secunia2009,
author = {Secunia},
title = {{Computer Security Research - Secunia}},
url = {https://secuniaresearch.flexerasoftware.com/community/research/},
urldate = {2018-12-12},
year = {2009}
}
@book{Whitman2011,
author = {Whitman, Michael E and Mattord, Herbert J},
publisher = {Cengage Learning},
title = {{Principles of information security}},
year = {2011}
}
@article{Aparecido2014,
abstract = {Um dos ativos de valor das empresas {\'{e}} a informa{\c{c}}{\~{a}}o, com destaque para a sua prote{\c{c}}{\~{a}}o, pois muitas vulnerabilidades e ataques s{\~{a}}o conhecidos e, a cada dia, novos s{\~{a}}o descobertos. Manter o parque computacional das empresas atualizado e protegido das vulnerabilidades {\'{e}} um trabalho minucioso, podendo ser auxiliado por softwares de an{\'{a}}lise de vulnerabilidades, que automatizam e facilitam o rastreamento dessas vulnerabilidades. Este artigo aborda dois destes softwares, o OpenVAS e o Nessus, e faz a compara{\c{c}}{\~{a}}o d os resultados da varredura de ambos. Foi poss{\'{i}}vel verificar que os softwares testados foram capazes de detectar as vulnerabilidades conhecidas no ambiente utilizado.},
author = {Aparecido, Cl{\'{e}}riston Aparecido Gomes Martinelo and Bellezi, Marcos Augusto},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/An{\'{a}}lise de Vulnerabilidades com OpenVAS e Nessus.pdf:pdf},
keywords = {Nessus.,OpenVAS,an{\'{a}}lise de vulnerabilidade,seguran{\c{c}}a de redes},
pages = {34--44},
title = {{An{\'{a}}lise de Vulnerabilidades com OpenVAS e Nessus}},
year = {2014}
}
@article{Mohurle2017,
author = {Mohurle, Savita and Patil, Manisha},
doi = {10.1046/j.1365-2427.2003.00982.x},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/A brief study of Wannacry.pdf:pdf},
issn = {0976-5697},
journal = {International Journal of Advanced Research in Computer Science (IJARCS)},
keywords = {decrypt,encrypt,preventive measures,ransomware,security,threat,wannacry},
number = {5},
pages = {1938--1940},
title = {{A brief study of Wannacry Threat: Ransomware Attack 2017}},
url = {http://www.ijarcs.info/index.php/Ijarcs/article/view/4021},
volume = {8},
year = {2017}
}
@article{technologies2018,
author = {Positive, Technologies},
title = {{Vulnerabilities In Corporate Information Systems}},
year = {2018}
}
@article{article,
author = {Shameli-Sendi, Alireza and Aghababaei-Barzegar, Rouzbeh and Cheriet, Mohamed},
doi = {10.1016/j.cose.2015.11.001},
journal = {Computers {\&} Security},
title = {{Taxonomy of Information Security Risk Assessment (ISRA)}},
volume = {57},
year = {2015}
}
@article{Goel2015,
abstract = {Complexity of systems are increasing day by day. This leads to more and more vulnerabilities in Systems. Attackers use these vulnerabilities to exploit the victim's system. It is better to find out these vulnerabilities in advance before attacker do. The power of Vulnerability assessment is usually underestimated. While Vulnerability Assessment and Penetration Testing can be used as a cyber-defence technology to provide proactive cyber defence. In this paper we proved Vulnerability Assessment and Penetration Testing (VAPT) as a Cyber defence technology, how we can provide active cyber defence using Vulnerability Assessment and Penetration Testing. We described complete life cycle of Vulnerability Assessment and Penetration Testing on systems or networks and proactive action taken to resolve that vulnerability and stop possible attack. In this paper we have described prevalent Vulnerability assessment techniques and some famous premium/open source VAPT tools. We have described complete process of how to use Vulnerability Assessment and Penetration Testing as a powerful Cyber Defence Technology.},
author = {Goel, Jai Narayan and Mehtre, B. M.},
doi = {10.1016/j.procs.2015.07.458},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/Vulnerability Assessment {\&} Penetration Testing as a Cyber Defence Technology.pdf:pdf},
isbn = {9183329005},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Cyberdefence,Cyberdefence Technology,Penetration Testing,System Security,VAPT Tools,Vulnerability Assessment},
pages = {710--715},
publisher = {Elsevier Masson SAS},
title = {{Vulnerability Assessment {\&} Penetration Testing as a Cyber Defence Technology}},
url = {http://dx.doi.org/10.1016/j.procs.2015.07.458},
volume = {57},
year = {2015}
}
@inproceedings{Musa:1984:LPE:800054.801975,
address = {Piscataway, NJ, USA},
author = {Musa, J D and Okumoto, K},
booktitle = {Proceedings of the 7th International Conference on Software Engineering},
isbn = {0-8186-0528-6},
pages = {230--238},
publisher = {IEEE Press},
series = {ICSE '84},
title = {{A Logarithmic Poisson Execution Time Model for Software Reliability Measurement}},
url = {http://dl.acm.org/citation.cfm?id=800054.801975},
year = {1984}
}
@article{Alhazmi2006,
abstract = {Quantitative approaches for software security are needed for effective testing, maintenance and risk assessment of software systems. Vulnerabilities that are present in an operating system after its release represent a great risk. Vulnerability discovery models (VDMs) have been proposed to model vulnerability discovery and have has been fined to vulnerability data against calendar time. The models have been shown to fit very well. In this paper, we investigate the prediction capabilities that these models offer by evaluating accuracy of predictions made with partial data. We examine both the recently proposed logistic model and a new linear model. In addition to VDMs, we consider static approaches to estimating some of the major attributes of the vulnerability discovery process, presenting a static approach to estimating the initial values of one of the VDM's parameters. We also suggest the use of constraints for parameter estimation during curve-fitting. Here we develop computational approaches for early applications of the models and examine the predictive capability of the models. We use data from Windows 98, Windows 2000 and Red Hat Linux 7.1. We examine the impact of using a specific constraint when the parameters of the logistic model are estimated plots for the prediction error are given. The results demonstrate that the prediction error is significantly less when a constraint based on past observations is added. It is observed that the linear model may yield acceptable projections for systems for which vulnerability discovery has not yet reached saturation. The results also suggest that it may be possible to improve the prediction capability by combining static and dynamic approaches, or by combing different models},
author = {Alhazmi, Omar H. and Malaiya, Yashwant K.},
doi = {10.1109/RAMS.2006.1677355},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/Prediction capabilities of vulnerabilities discovery models.pdf:pdf},
isbn = {1424400074},
issn = {0149144X},
journal = {Proceedings - Annual Reliability and Maintainability Symposium},
keywords = {Intrusions,Operating systems,Quantitative models,Security holes,Vulnerability},
number = {Ref 2},
pages = {86--91},
pmid = {11746262},
title = {{Prediction capabilities of vulnerability discovery models}},
year = {2006}
}
@misc{CVE1985,
author = {CVE},
title = {{CVE - Common Vulnerabilities and Exposures (CVE)}},
url = {https://cve.mitre.org/},
urldate = {2018-11-12},
year = {1985}
}
@article{Bhatt2017,
author = {Bhatt, Navneet and Anand, Adarsh},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/Modeling and characterizing software vulnerabilities.pdf:pdf},
keywords = {software security,vulnerability categorization,vulnerability discovery modeling},
number = {4},
pages = {288--299},
title = {{Modeling and Characterizing Software Vulnerabilities}},
volume = {2},
year = {2017}
}
@article{Spanceski2004,
author = {Spanceski, Francini Reitz},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/POL{\'{I}}TICA DE SEGURAN{\c{C}}A.pdf:pdf},
title = {{Pol{\'{i}}tica De Seguran{\c{c}}a Da Informa{\c{c}}{\~{a}}o – Desenvolvimento De Um Modelo Voltado Para Institui{\c{c}}{\~{o}}es De Ensino}},
year = {2004}
}
@book{Fontes2017,
author = {Fontes, Edison Luiz Gon{\c{c}}alves},
publisher = {Editora Saraiva},
title = {{Seguran{\c{c}}a da Informa{\c{c}}{\~{a}}o}},
year = {2017}
}
@misc{Arsham,
author = {Arsham, Hossein},
title = {{Time Series Analysis for Business Forecasting}},
url = {http://home.ubalt.edu/ntsbarsh/Business-stat/stat-data/Forecast.htm},
urldate = {2018-10-15},
year = {1994}
}
@misc{NVD,
author = {NIST},
title = {{NVD - Home}},
url = {https://nvd.nist.gov/},
urldate = {2018-09-26},
year = {2004}
}
@article{Brown,
author = {Brown, David S and Longstaff, Thomas A},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/Responding to computer security incidents Guidelines for incident handling.pdf:pdf},
journal = {ReVision},
title = {{Responding To Computer Security Incidents : Guidelines for Incident Handling}}
}
@article{Anjum2013,
author = {Anjum, Mohd. and Haque, Md. Asraful and Ahmad, Nesar},
doi = {10.5815/ijitcs.2013.02.01},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/Analysis and Ranking of Software Reliability.pdf:pdf},
issn = {20749007},
journal = {International Journal of Information Technology and Computer Science},
number = {2},
pages = {1--14},
title = {{Analysis and Ranking of Software Reliability Models Based on Weighted Criteria Value}},
url = {http://www.mecs-press.org/ijitcs/ijitcs-v5-n2/v5n2-1.html},
volume = {5},
year = {2013}
}
@article{Zhao2014,
abstract = {Copyright ? 2014 by the Association for Computing Machinery, Inc. (ACM).White hats are making significant contributions to cybersecurity by submitting vulnerability discovery reports to public vulnerability disclosure programs and company-initiated vulnerability reward programs. In this paper, we study white hat behaviors by analyzing a 3.5-year dataset which documents the contributions of 3254 white hats and their submitted 16446 Web vulnerability reports. Our dataset is collected from Wooyun, the predominant Web vulnerability disclosure program in China. We first show that Wooyun is continuously attracting new contributors from the white hat community. We then examine white hats' contributions along several dimensions. In particular, we provide evidence about the diversity inside Wooyun's white hat community and discuss the importance of this diversity for vulnerability discovery. Our results suggest that more participation, and thereby more diversity, contributes to higher productivity of the vulnerability discovery process.},
author = {Zhao, Mingyi and Grossklags, Jens and Chen, Kai},
doi = {10.1145/2663887.2663906},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/An Exploratory Study of White Hat Behaviors in a Web Vulnerability Disclosure Program.pdf:pdf},
isbn = {9781450331524},
issn = {15437221},
journal = {Proceedings of the 2014 ACM Workshop on Security Information Workers - SIW '14},
keywords = {behavior,vulnerability disclosure,vulnerability discovery},
pages = {51--58},
title = {{An Exploratory Study of White Hat Behaviors in a Web Vulnerability Disclosure Program}},
url = {http://dl.acm.org/citation.cfm?doid=2663887.2663906},
year = {2014}
}
@article{Woo2006a,
abstract = {New vulnerabilities discovered in a web browser put millions of users at risk, requiring urgent attention from developers to address these vulnerabilities. This paper presents a quantitative characterization of browser vulnerabilities which can be used to project the number of vulnerabilities to plan, test and development resources more efficiently. Vulnerability discovery data for the three major browsers, Internet Explore, Firefox and Mozilla, are examined and fitted to a vulnerability discovery model, and the goodness of fit is statistically examined. The results show that the datasets fit the model well, suggesting that this model can be used for making future projections. When the vulnerabilities are partitioned into categories based on their type, the data of individual categories also fit the model separately. When the vulnerabilities are partitioned into three severity levels, the model is found to be applicable to vulnerabilities with high and low severities. It is observed that the popularity of a browser itself leads to a higher discovery rate.},
author = {Woo, SW and Alhazmi, OH and Malaiya, YK},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/AN ANALYSIS OF THE VULNERABILITY DISCOVERY PROCESS.pdf:pdf},
isbn = {9780889865990},
journal = {Proceedings of the 10th IASTED International Conference},
keywords = {firefox,internet explorer,vulnerability,web browser},
pages = {172--177},
title = {{An analysis of the vulnerability discovery process in web browsers}},
url = {http://www.cs.colostate.edu/{~}malaiya/pub/wooSEA{\_}2006.pdf},
year = {2006}
}
@article{Last2015,
abstract = {The field of network and computer security is a never-ending race with attackers, trying to identify and patch software vulnerabilities before they can be exploited. In this ongoing conflict, it would be quite useful to be able to predict when and where the next software vulnerability would appear. The research presented in this paper is the first step towards a capability for forecasting vulnerability discovery rates for individual software packages. This first step involves creating forecast models for vulnerability rates at the global level, as well as the category (web browser, operating system, and video player) level. These models will later be used as a factor in the predictive models for individual software packages. A number of regression models are fit to historical vulnerability data from the National Vulnerability Database (NVD) to identify historical trends in vulnerability discovery. Then, k-NN classification is used in conjunction with several time series distance measurements to select the appropriate regression models for a forecast. 68{\%} and 95{\%} confidence bounds are generated around the actual forecast to provide a margin of error. Experimentation using this method on the NVD data demonstrates the accuracy of these forecasts, as well as the accuracy of the confidence bounds forecasts. Analysis of these results indicates which time series distance measures produce the best vulnerability discovery forecasts.},
author = {Last, David},
doi = {10.1109/RWEEK.2015.7287429},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/Using Historical Software Vulnerability Data.pdf:pdf},
isbn = {9781479985944},
journal = {Proceedings - 2015 Resilience Week, RSW 2015},
keywords = {cybersecurity,vulnerability discovery model,vulnerability prediction},
pages = {120--126},
title = {{Using historical software vulnerability data to forecast future vulnerabilities}},
year = {2015}
}
@article{Rahimi2013,
abstract = {Predicting software vulnerability discovery trends can help improve secure deployment of software applications and facilitate backup provisioning, disaster recovery, diversity planning, and maintenance scheduling. Vulnerability discovery models (VDMs) have been studied in the literature as a means to capture the underlying stochastic process. Based on the VDMs, a few vulnerability prediction schemes have been proposed. Unfortunately, all these schemes suffer from the same weaknesses: they require a large amount of historical vulnerability data from a database (hence they are not applicable to a newly released software application), their precision depends on the amount of training data, and they have significant amount of error in their estimates. In this work, we propose vulnerability scrying, a new paradigm for vulnerability discovery prediction based on code properties. Using compiler-based static analysis of a codebase, we extract code properties such as code complexity (cyclomatic complexity), and more importantly code quality (compliance with secure coding rules), from the source code of a software application. Then we propose a stochastic model which uses code properties as its parameters to predict vulnerability discovery. We have studied the impact of code properties on the vulnerability discovery trends by performing static analysis on the source code of four real-world software applications. We have used our scheme to predict vulnerability discovery in three other software applications. The results show that even though we use no historical data in our prediction, vulnerability scrying can predict vulnerability discovery with better precision and less divergence over time.},
author = {Rahimi, Sanaz and Zargham, Mehdi},
doi = {10.1109/TR.2013.2257052},
file = {:C$\backslash$:/Users/Ari/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rahimi, Zargham - 2013 - Vulnerability scrying method for software vulnerability discovery prediction without a vulnerability database.pdf:pdf},
issn = {00189529},
journal = {IEEE Transactions on Reliability},
keywords = {Code security,static analysis,vulnerability discovery model,vulnerability prediction},
number = {2},
pages = {395--407},
title = {{Vulnerability scrying method for software vulnerability discovery prediction without a vulnerability database}},
volume = {62},
year = {2013}
}
@article{Woo2006,
author = {Woo, Sung Whan and Alhazmi, Omar H. and Malaiya, Yashwant K.},
doi = {10.1109/DASC.2006.21},
file = {:C$\backslash$:/Users/Ari/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Woo, Alhazmi, Malaiya - 2006 - Assessing vulnerabilities in apache and IIS HTTP servers.pdf:pdf},
isbn = {0769525393},
journal = {Proceedings - 2nd IEEE International Symposium on Dependable, Autonomic and Secure Computing, DASC 2006},
number = {January},
pages = {103--110},
title = {{Assessing vulnerabilities in apache and IIS HTTP servers}},
year = {2006}
}
@article{Ozment2007,
author = {Ozment, Andy and Engineering, D Software},
doi = {10.1145/1314257.1314261},
file = {:C$\backslash$:/Users/Ari/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ozment, Engineering - 2007 - Improving Vulnerability Discovery Models Problems with Definitions and Assumptions Categories and Subject D.pdf:pdf},
isbn = {9781595938855},
issn = {15437221},
journal = {Cycle},
keywords = {air force contract,by the i3p under,measuring,measuring vulnerabilities,security metrics,software security,this work is sponsored,vulnerability discovery models},
pages = {6--11},
title = {{Improving Vulnerability Discovery Models Problems with Definitions and Assumptions Categories and Subject Descriptors}},
year = {2007}
}
@article{Anderson2002,
abstract = {一种弱点发现率的模型 使用热力学中的知识},
author = {Anderson, R},
file = {:C$\backslash$:/Users/Ari/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Anderson - 2002 - Security in Open versus Closed Systems–The Dance of Boltzmann, Coase and Moore.pdf:pdf},
journal = {at Open Source Software Economics},
pages = {127--142},
title = {{Security in Open versus Closed Systems–The Dance of Boltzmann, Coase and Moore}},
year = {2002}
}
@article{Joh,
author = {Joh, Hyunchul and Malaiya, Yashwant K and Xp, Win},
file = {:C$\backslash$:/Users/Ari/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Joh, Malaiya, Xp - Unknown - Modeling Skewness in Vulnerability Discovery Models in Major Operating Systems.pdf:pdf},
keywords = {-vulnerability discovery model,assessment,operating systems,risk,s-shaped distribution,security,vdm},
pages = {406--407},
title = {{Modeling Skewness in Vulnerability Discovery Models in Major Operating Systems}}
}
@article{Alhazmi2005b,
abstract = {Security vulnerabilities in servers and operating systems are software defects that represent great risks. Both software developers and users are struggling to contain the risk posed by these vulnerabilities. The vulnerabilities are discovered by both developers and external testers throughout the life-span of a software system. A few models for the vulnerability discovery process have just been published recently. Such models will allow effective resource allocation for patch development and are also needed for evaluating the risk of vulnerability exploitation. Here we examine these models for the vulnerability discovery process. The models are examined both analytically and using actual data on vulnerabilities discovered in three widely-used systems. The applicability of the proposed models and significance of the parameters involved are discussed. The limitations of the proposed models are examined and major research challenges are identified},
author = {Alhazmi, O H and Malaiya, Y K},
doi = {10.1109/ISSRE.2005.30},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/Modeling the Vulnerability Discovery Process.pdf:pdf},
isbn = {0769524826},
issn = {10719458},
journal = {Proceedings - International Symposium on Software Reliability Engineering, ISSRE},
pages = {129--138},
title = {{Modeling the vulnerability discovery process}},
volume = {2005},
year = {2005}
}
@article{Shiibashi2007a,
abstract = {High-load transaction systems such as the IC (Integrated Circuit) Card Ticket System require high performance, high reliability, and service continuity. However, the wireless communications have a problem that higher performance at the gates results in lower reliability in the data. The solution is the Autonomous Decentralized Architecture, in which "IC cards," "terminals," and a "center server" are designed as the autonomous nodes. Based on the architecture, two technologies have been introduced: "Autonomous Decentralized Fare Calculation Algorithm" for high performance and "Autonomous Decentralized Data Consistency Technology" for high reliability. This paper looks into the Multi-layered Data Consistency Technology which assures service continuity, using heterogeneous data fields with various time ranges. Appropriate values are considered through theorization, modeling, and simulation. These conditions are used in the practical "Suica" system at East Japan Railway Company and the system is running satisfactory, without any fatal errors. {\^{A}}{\textcopyright} 2007 IEEE.},
author = {Shiibashi, Akio and Nakaniwa, Tsuyoshi and Yamana, Motoharu and Mori, Kinji},
doi = {10.1109/HASE.2007.55},
file = {:C$\backslash$:/Users/Ari/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shiibashi et al. - 2007 - Multi-layered data consistency technology, an enhanced autonomous decentralized data consistency technology fo.pdf:pdf},
isbn = {0769530435},
issn = {15302059},
journal = {Proceedings of IEEE International Symposium on High Assurance Systems Engineering},
number = {March 2017},
pages = {219--226},
title = {{Multi-layered data consistency technology, an enhanced autonomous decentralized data consistency technology for IC card ticket system}},
year = {2007}
}
@inproceedings{Joh2008a,
abstract = {A vulnerability discovery model describes the variation in the vulnerability discovery rate during the lifetime of a software system and can be used to assess risk and to evaluate possible mitigation approaches. A few vulnerability discovery models have recently been proposed. The AML Logistic model has been found to provide the best fit in several cases. Weibull distribution, which can model an asymmetric pdf, is often used for reliability evaluation in some fields but has not been used for modeling vulnerability discovery. Here we propose a new Weibull distribution based on vulnerability discovery model and compare it with the existing AML Model. The results show that the new model performs well in many cases, and may be considered as an alternative to the AML model.},
author = {Joh, HyunChul and Jinyoo, Kim and Malaiya, Yashwant K},
booktitle = {Proceedings - International Symposium on Software Reliability Engineering, ISSRE},
doi = {10.1109/ISSRE.2008.32},
file = {:C$\backslash$:/Users/Ari/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Joh, Jinyoo, Malaiya - 2008 - Vulnerability discovery modeling using weibull distribution.pdf:pdf},
isbn = {9780769534053},
issn = {10719458},
pages = {299--300},
title = {{Vulnerability discovery modeling using weibull distribution}},
year = {2008}
}
@article{Rescorla2005,
abstract = {Despite the large amount of effort that goes toward finding and patching security holes, the available data does not show a clear improvement in software quality as a result. This article aims to measure the effect of vulnerability finding. Any attempt to measure this kind of effect is inherently rough, depending as it does on imperfect data and several simplifying assumptions. Because I'm looking for evidence of usefulness, where possible, I bias such assumptions in favor of a positive result - explicitly calling out those assumptions biased in the opposite direction. Thus, the analysis in this article represents the best-case scenario, consistent with the data and my ability to analyze it, for the vulnerability finding's usefulness},
author = {Rescorla, Eric},
doi = {10.1109/MSP.2005.17},
file = {:C$\backslash$:/Users/Ari/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rescorla - 2005 - Is finding security holes a good idea.pdf:pdf},
issn = {15407993},
journal = {IEEE Security and Privacy},
number = {1},
pages = {14--19},
title = {{Is finding security holes a good idea?}},
volume = {3},
year = {2005}
}
@book{Bowerman1987,
author = {Bowerman, B L and O'Connell, R T},
isbn = {9780871500700},
publisher = {Duxbury Press},
title = {{Time series forecasting: unified concepts and computer implementation}},
url = {https://books.google.com.br/books?id=h1QZAQAAIAAJ},
year = {1987}
}
@article{Joh2009,
abstract = {Vulnerability discovery rates need to be taken into account for evaluating security risks. Accurate projection of these rates is required to estimate the effort needed to develop patches for handling vulnerabilities discovered. Seasonal behaviors of the vulnerability discovery process for a multi-year life-cycle of software products are examined. A careful inspection of the data for several major operating systems, web servers and web browsers suggests presence of a seasonal behavior that is not considered by the vulnerability discovery models. This paper examines the statistical significance of the annual seasonal pattern in the vulnerability discovery rates using the seasonal index approach. The autocorrelation function is used to identify the periodicity. A time series analysis that combines thelonger term trends with cycles caused by seasonality may predict the future pattern more accurately. The analysis of the datasets for eight major operating systems and four web related software systems (Windows NT, XP, 2000, Server 2003, MAC OS X, HPUX, Solaris, Red Hat Linux, IIS, Apache, Internet Explorer and Firefox) shows that there is indeed anannual seasonal pattern. While all the programs exhibit a year-end peak, a higher incidence is also observed during the mid-year months for Microsoft products.},
author = {Joh, HyunChul and Malaiya, Yashwant K.},
doi = {10.1109/ICST.2009.9},
file = {:C$\backslash$:/Users/Ari/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Joh, Malaiya - 2009 - Seasonal variation in the vulnerability discovery process.pdf:pdf},
isbn = {9780769536019},
issn = {2159-4848},
journal = {Proceedings - 2nd International Conference on Software Testing, Verification, and Validation, ICST 2009},
pages = {191--200},
title = {{Seasonal variation in the vulnerability discovery process}},
year = {2009}
}
@article{Borges2018,
author = {Borges, Ariane Santos},
file = {:C$\backslash$:/Users/Ari/Downloads/tcc-ariane-atual.pdf:pdf},
title = {{An{\'{a}}lise da varia{\c{c}}{\~{a}}o sazonal do processo de descoberta de vulnerabilidades de seguran{\c{c}}a}},
year = {2018}
}
@article{Alhazmi2007,
abstract = {In this work we examine the feasibility of quantitatively characterizing some aspects of security. In particular, we investigate if it is possible to predict the number of vulnerabilities that can potentially be present in a software system but may not have been found yet. We use several major operating systems as representatives of complex software systems. The data on vulnerabilities discovered in these systems are analyzed. We examine the results to determine if the density of vulnerabilities in a program is a useful measure. We also address the question about what fraction of software defects are security related, i.e., are vulnerabilities. We examine the dynamics of vulnerability discovery hypothesizing that it may lead us to an estimate of the magnitude of the undiscovered vulnerabilities still present in the system. We consider the vulnerability discovery rate to see if models can be developed to project future trends. Finally, we use the data for both commercial and open-source systems to determine whether the key observations are generally applicable. Our results indicate that the values of vulnerability densities fall within a range of values, just like the commonly used measure of defect density for general defects. Our examination also reveals that it is possible to model the vulnerability discovery using a logistic model that can sometimes be approximated by a linear model. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Alhazmi, O. H. and Malaiya, Y. K. and Ray, I.},
doi = {10.1016/j.cose.2006.10.002},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/Measuring, analyzing and predicting security vulnerabilities in software systems.pdf:pdf},
isbn = {0167-4048},
issn = {01674048},
journal = {Computers and Security},
keywords = {Defect density,Quantitative security modeling,Risk evaluation,Security holes,Vulnerabilities},
number = {3},
pages = {219--228},
title = {{Measuring, analyzing and predicting security vulnerabilities in software systems}},
volume = {26},
year = {2007}
}
@article{Joh2016,
author = {Joh, HyunChul and Malaiya, Yashwant K.},
doi = {10.1007/s10207-016-0345-x},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/Periodicity in software vulnerability discovery, patching and exploitation.pdf:pdf},
issn = {1615-5262},
journal = {International Journal of Information Security},
keywords = {Laws of vulnerabilities,Operating system,Periodicity,Seasonality,Vulnerability,laws of vulnerabilities,operating system,periodicity,seasonality,vulnerability},
publisher = {Springer Berlin Heidelberg},
title = {{Periodicity in software vulnerability discovery, patching and exploitation}},
url = {http://link.springer.com/10.1007/s10207-016-0345-x},
year = {2016}
}
@article{Miani2013,
author = {Miani, Rodrigo Sanches},
file = {:C$\backslash$:/Users/Ari/Dropbox/Ariane/Ref/Monografias/Miani - 2013 - Um estudo sobre m{\'{e}}tricas e quantifica{\c{c}}{\~{a}}o em seguran{\c{c}}a da informa{\c{c}}{\~{a}}o-annotated.pdf:pdf},
title = {{Um estudo sobre m{\'{e}}tricas e quantifica{\c{c}}{\~{a}}o em seguran{\c{c}}a da informa{\c{c}}{\~{a}}o}},
year = {2013}
}
@article{Alhazmi2008,
abstract = {A number of security vulnerabilities have been reported in the Windows, and Linux operating systems. Both the developers, and users of operating systems have to utilize significant resources to evaluate, and mitigate the risk posed by these vulnerabilities. Vulnerabilities are discovered throughout the life of a software system by both the developers, and external testers. Vulnerability discovery models are needed that describe the vulnerability discovery process for determining readiness for release, future resource allocation for patch development, and evaluating the risk of vulnerability exploitation. Here, we analytically describe six models that have been recently proposed, and evaluate those using actual data for four major operating systems. The applicability of the proposed models, and the significance of the parameters involved are examined. The results show that some of the models tend to capture the discovery process better than others.},
author = {Alhazmi, Omar H and Malaiya, Yashwant K},
doi = {10.1109/TR.2008.916872},
file = {:C$\backslash$:/Users/Ari/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Alhazmi, Malaiya - 2008 - Application of vulnerability discovery models to major operating systems.pdf:pdf},
issn = {00189529},
journal = {IEEE Transactions on Reliability},
keywords = {Operating systems,Security,Software reliability growth models,Vulnerabilities,Vulnerability discovery},
number = {1},
pages = {14--22},
title = {{Application of vulnerability discovery models to major operating systems}},
volume = {57},
year = {2008}
}
@article{Massacci2014,
abstract = {Vulnerability discovery models (VDMs) operate on known vulnerability data to estimate the total number of vulnerabilities that will be reported after a software is released. VDMs have been proposed by industry and academia, but there has been no systematic independent evaluation by researchers who are not model proponents. Moreover, the traditional evaluation methodology has some issues that biased previous studies in the field. In this work we propose an empirical methodology that systematically evaluates the performance of VDMs along two dimensions (quality and predictability) and addresses all identified issues of the traditional methodology. We conduct an experiment to evaluate most existing VDMs on popular web browsers' vulnerability data. Our comparison shows that the results obtained by the proposed methodology are more informative than those by the traditional methodology. Among evaluated VDMs, the simplest linear model is the most appropriate choice in terms of both quality and predictability for the first 6-12 months since a release date. Otherwise, logistics-based models are better choices.},
author = {Massacci, Fabio and Nguyen, Viet Hung},
doi = {10.1109/TSE.2014.2354037},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/An Empirical Methodology to Evaluate Vulnerability Discovery Models.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Empirical evaluation,Software security,Vulnerability analysis,Vulnerability discovery model},
number = {12},
pages = {1147--1162},
title = {{An empirical methodology to evaluate vulnerability discovery models}},
volume = {40},
year = {2014}
}
@article{International2016,
abstract = {Network security is one of the major concerns of world. We all know that the systems on the internet are increasing day by day and so the vulnerabilities. These vulnerabilities must be found before the attacker. This can be done with the help of penetration testing. Penetration testing is used to check or evaluate the security posture of an organization or network. Its job is to provide the all round investigation for finding the vulnerabilities and security threats in different systems and networks. This paper explains the penetration testing and methodology for performing it. It also discusses the prevalent tools and techniques for information gathering and vunerability assessment. And finally penetration testing frameworks are analyzed so as to find the vulnerabilities so that patches can be made to fill and increase the security of system, network or applications.},
author = {Singh, Harmandeep and Surender, J and Pankaj, K V},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/Penetration{\_}Testing{\_}Analyzing{\_}the{\_}Security.pdf:pdf},
journal = {Ijltemas},
keywords = {-Vunerability assessment,Immunity Canvas,core impact,exploits,metasploit,penetration testing tools},
number = {V},
pages = {56--60},
title = {{Penetration Testing: Analyzing the Security of the Network by Hacker's Mind}},
volume = {V},
year = {2016}
}
@article{Joh2008b,
abstract = {Prediction of vulnerability discovery rates can be used to assess security risks and to determine the resources needed to develop patches quickly to handle vulnerabilities discovered. An examination of the vulnerability data suggests a seasonal behavior that has not been modeled by the recently proposed vulnerability discovery models. This seasonality has not been identified or examined so far. This study examines whether vulnerability discovery rates for Windows NT, IIS Server and the Internet Explorer exhibit a significant annual seasonal pattern. Actual data has been analyzed using seasonal index and auto correlation function approaches to identify seasonality and to evaluate its statistical significance. The results for the three software systems show that there is indeed a significant annual seasonal pattern.},
author = {Joh, HyunChul and Malaiya, Yashwant K.},
doi = {10.1109/ISSRE.2008.31},
file = {:C$\backslash$:/Users/Ari/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Joh, Malaiya - 2008 - Seasonality in vulnerability discovery in major software systems.pdf:pdf},
isbn = {9780769534053},
issn = {10719458},
journal = {Proceedings - International Symposium on Software Reliability Engineering, ISSRE},
pages = {297--298},
title = {{Seasonality in vulnerability discovery in major software systems}},
year = {2008}
}
@article{Younis2011,
abstract = {– A vulnerability discovery model describes the vulnerability discovery rate in a software system, and pre-dicts the future behavior. It can allow the IT managers and developers to allocate their resources optimally by timely development and application of patches. Such models also allow the end-users to assess security risk in their systems. Recently, researchers have proposed a few vulnerability discovery models. The models are based on different as-sumptions, and thus differ in their accuracy and prediction capabilities. Among these models, the AML model has been found to have performed better in many cases in terms of model fitting and prediction capabilities. The AML model assumes that the discovery rate is symmetric. However, it has been noted that there are cases when the discovery trend is asymmetric. In this paper, we investigate the ap-plicability of using a new vulnerability discovery model called Folded model, based on the Folded normal distribu-tion, and compare it with the AML model. Results show that Folded model performs better than the AML model in gen-eral for both model fitting and prediction capabilities in cases when the learning phase is not present.},
author = {Younis, Awad and Joh, HyunChul and Malaiya, Yashwant},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/Modeling learningless vulnerability discovery using a folded distribution.pdf:pdf},
journal = {Proc. of SAM},
keywords = {3,4,5,aml,and alhazmi-,anderson,based on,each of them is,folded model,malaiya logistic,model,risk assessment,s thermodynamic model,software security,vdm,vulnerability discovery},
pages = {617--623},
title = {{Modeling learningless vulnerability discovery using a folded distribution}},
url = {http://www.lidi.info.unlp.edu.ar/WorldComp2011-Mirror/SAM8765.pdf},
volume = {11},
year = {2011}
}
@article{Condon2008,
abstract = {Organizations face increasing challenges in addressing and preventing computer and network security incidents. There are financial consequences from security incidents. These include lost time and resources used during recovery, possible theft of personal and/or proprietary information, and reputational damage that may negatively impact stock prices or reduce consumer confidence in a company. Being able to understand and predict trends in computer and network security incidents can aid an organization with resource allocation for prevention of such incidents, as well as evaluation of mitigation strategies. We look at using time series models with a large set of security incident data. We examine appropriateness of the data for modeling and consider needed transformations. Parameter search and model selection criteria are discussed. Then, forecasts from time series models are compared to forecasts from Non-Homogeneous Poisson Process (NHPP) software reliability growth (SRG) models.},
author = {Condon, Edward and He, Angela and Cukier, Michel},
doi = {10.1109/ISSRE.2008.39},
file = {:C$\backslash$:/Users/Ari/Dropbox/Ariane/Ref/Artigos/Analysis of Computer Security Incident Data Using Time Series Models.pdf:pdf},
issn = {1071-9458},
journal = {2008 19th International Symposium on Software Reliability Engineering (ISSRE)},
pages = {77--86},
title = {{Analysis of Computer Security Incident Data Using Time Series Models}},
url = {http://ieeexplore.ieee.org/document/4700312/},
year = {2008}
}
@article{HungNguyen,
abstract = {A precise vulnerability discovery model (VDM) will provide a useful insight to assess software security, and could be a good prediction instrument for both software vendors and users to understand security trends and plan ahead patching schedule accordingly. Thus far, several models have been proposed and validated. Yet, no systematically independent validation by somebody other than the author exists. Furthermore, there are a number of issues that might bias previous studies in the field. In this work, we fill in the gap by introducing an empirical methodology that systematically evaluates the performance of a VDM in two aspects: quality and predictability. We further apply this methodology to assess existing VDMs. The results show that some models should be rejected outright, while some others might be adequate to capture the discovery process of vulnerabilities. We also consider different usage scenarios of VDMs and find that the simplest linear model is the most appropriate choice in terms of both quality and predictability when browsers are young. Otherwise, logistics-based models are better choices.},
archivePrefix = {arXiv},
arxivId = {1306.2476},
author = {Nguyen, Viet Hung and Massacci, Fabio},
eprint = {1306.2476},
file = {:C$\backslash$:/Users/Ari/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Massacci - 2013 - A Systematically Empirical Evaluation of Vulnerability Discovery Models a Study on Browsers' Vulnerabilities.pdf:pdf},
keywords = {Empirical Validation,Index Terms—Software Security,Vulnerability Analysis !,Vulnerability Discovery Model},
title = {{A Systematically Empirical Evaluation of Vulnerability Discovery Models: a Study on Browsers' Vulnerabilities}},
url = {http://arxiv.org/abs/1306.2476},
year = {2013}
}
@article{Zimmermann2010,
abstract = {Many factors are believed to increase the vulnerability of software system; for example, the more widely deployed or popular is a software system the more likely it is to be attacked. Early identification of defects has been a widely investigated topic in software engineering research. Early identification of software vulnerabilities can help mitigate these attacks to a large degree by focusing better security verification efforts in these components. Predicting vulnerabilities is complicated by the fact that vulnerabilities are, most often, few in number and introduce significant bias by creating a sparse dataset in the population. As a result, vulnerability prediction can be thought of us preverbally “searching for a needle in a haystack.” In this paper, we present a large-scale empirical study on Windows Vista, where we empirically evaluate the efficacy of classical metrics like complexity, churn, coverage, dependency measures, and organizational structure of the company to predict vulnerabilities and assess how well these software measures correlate with vulnerabilities. We observed in our experiments that classical software measures predict vulnerabilities with a high precision but low recall values. The actual dependencies, however, predict vulnerabilities with a lower precision but substantially higher recall.},
author = {Zimmermann, Thomas and Nagappan, Nachiappan and Williams, Laurie},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/Predicting Security Vulnerabilities for Windows Vista.pdf:pdf},
keywords = {churn,complexity,coverage,dependencies,metrics,organizational structure,prediction,vulnerabilities},
title = {{Searching for a Needle in a Haystack: Predicting Security Vulnerabilities for Windows Vista}},
year = {2010}
}
@article{Ozment2006,
abstract = {We examine the code base of the OpenBSD operating system to determine whether its security is increasing over time. We measure the rate at which new code has been introduced and the rate at which vulnerabili- ties have been reported over the last 7.5 years and fifteen versions. We learn that 61{\%} of the lines of code in todays OpenBSD are foundational: they were introduced prior to the release of the initial version we studied and have not been altered since. We also learn that 62{\%} of re- ported vulnerabilities were present when the study began and can also be considered to be foundational. We find strong statistical evidence of a decrease in the rate at which foundational vulnerabilities are being re- ported. However, this decrease is anything but brisk: foundational vulnerabilities have a median lifetime of at least 2.6 years. Finally, we examined the density of vulnerabilities in the code thatwas altered/introduced in each version. The densities ranged from 0 to 0.033 vulnerabilities reported per thousand lines of code. These densities will increase as more vulnerabilities are reported.},
author = {Ozment, Andy and Schechter, Stuart E},
file = {:C$\backslash$:/Users/Ari/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ozment, Schechter - 2006 - Milk or Wine Does Software Security Improve with Age.pdf:pdf},
journal = {15th USENIX Security Symposium (Security '06)},
pages = {93--104},
title = {{Milk or Wine : Does Software Security Improve with Age?}},
year = {2006}
}
@article{Musa2004,
author = {Musa, John D.},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/Software reliability engineering.pdf:pdf},
pages = {368},
title = {{Software Reliability Engineering}},
volume = {2},
year = {2004}
}
@article{Joh2011,
abstract = {There have been numerous studies addressing computer security and software vulnerability management. Most of the time, they have taken a qualitative perspective. In many other disciplines, quantitative analyses have been indispensable for performance assessment, metric measurement, functional evaluation, or statistical modeling. Quantitative approaches can also help to improve software risk management by providing guidelines obtained by using actual data-driven analyses for optimal allocations of resources for security testing, scheduling, and development of security patches. Quantitative methods allow objective and more accurate estimates of future trends than qualitative manners only because a quantitative approach uses real datasets with statistical methods which have proven to be a very powerful prediction approach in several research fields. A quantitative methodology makes it possible for end-users to assess the risks posed by vulnerabilities in software systems, and potential breaches without getting burdened by details of every individual vulnerability. At the moment, quantitative risk analysis in information security systems is still in its infancy stage. However, recently, researchers have started to explore various software vulnerability related attributes quantitatively as the vulnerability datasets have now become large enough for statistical analyses. In this dissertation, quantitative analysis is presented dealing with i) modeling vulnerability discovery processes in major Web servers and browsers, ii) relationship between the performance of S-shaped vulnerability discovery models and the skew in vulnerability datasets examined, iii) linear vulnerability discovery trends in multi-version software systems, iv) periodic behavior in weekly exploitation and patching of vulnerabilities as well as long term vulnerability discovery process, and v) software security risk evaluation with respect to the vulnerability lifecycle and CVSS. Results show good superior vulnerability discovery model fittings and reasonable prediction capabilities for both time-based and effort-based models for datasets from Web servers and browsers. Results also show that AML and Gamma distribution based models perform better than other S-shaped models with skewed left and right datasets respectively. We find that code sharing among the successive versions cause a linear discovery pattern. We establish that there are indeed long and short term periodic patterns in software vulnerability related activities which have been only vaguely recognized by the security researchers. Lastly, a framework for software security risk assessment is proposed which can allow a comparison of software systems in terms of the risk and potential approaches for optimization of remediation.},
author = {Joh, HyunChul},
file = {:C$\backslash$:/Users/Ari/Dropbox/UFU/UFU10/TCC2/Ref/Artigos/QUANTITATIVE ANALYSES OF SOFTWARE VULNERABILITIES.pdf:pdf},
isbn = {9781267097033},
journal = {ProQuest Dissertations and Theses},
keywords = {Applied sciences,Communication and the arts,Information security systems,Modeling,Quantitative analysis,Risk,Security,Software vulnerabilities,Vulnerability discovery process},
title = {{Quantitative analyses of software vulnerabilities}},
url = {http://search.proquest.com/docview/916925550?accountid=44888 LA  - English},
year = {2011}
}
@misc{ABNT2005,
abstract = {Deaths from cancer will continue to rise with an increasing and aging population. Family caregivers of patients with cancer will face loss, grief, and bereavement as a result. As mandated by cancer and palliative care clinical practice guidelines, support for family caregivers continues through the processes of grief and bereavement to facilitate a positive transition through loss. To provide evidence-based nursing with this population, an analysis of their context of care was undertaken. Key health policies, characteristics of the healthcare delivery system, and the results of research with bereaved palliative caregivers are described. A model of effectiveness, efficiency, and equity is used to examine the situation of bereaved caregivers and to suggest research questions to fill the gaps in what is known about their needs and experience. Bereaved caregivers are at high risk for many distressing symptoms, including depression and sleeplessness, related to a range of complex variables, such as age, gender, social support, resources, and their experiences during caregiving. Current systems of support have not been adequate to meet the needs of this population and very little is known about the caregivers' quality of life, well-being, and health outcomes or how best to provide compassionate and effective nursing care.},
author = {ABNT},
doi = {10.1188/08.CJON.501-506},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/NBR{\_}ISO{\_}27002.pdf:pdf},
isbn = {1092-1095},
issn = {1092-1095},
title = {{NBR{\_}ISO{\_}27002.pdf}},
url = {http://www.fieb.org.br/download/senai/NBR{\_}ISO{\_}27002.pdf},
year = {2005}
}
@book{Dantas2011,
abstract = {Auditor fiscal e Oficial da reserva da Pol{\'{i}}cia Militar de Pernambuco, possui trabalhos publicados e realizados nas {\'{a}}reas de seguran{\c{c}}a p{\'{u}}blica, privada, portu{\'{a}}ria, da informa{\c{c}}{\~{a}}o e de gest{\~{a}}o de riscos. {\'{E}} contador, graduado pela UFPE, e p{\'{o}}s-graduado em planejamento e gest{\~{a}}o organizacional pela FCAPE, e em Direito Tribut{\'{a}}rio pela UFPE. {\'{E}} Auditor L{\'{i}}der em Sistemas de Gest{\~{a}}o de Seguran{\c{c}}a da Informa{\c{c}}{\~{a}}o ISO 27001:2005.},
author = {Dantas, Marcus Leal.},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/seguranca{\_}informacao.pdf:pdf},
isbn = {9788540600478},
keywords = {Informa{\c{c}}{\~{a}}o – vulnerabilidades e amea{\c{c}}as,Neg{\'{o}}cios corporativos,Seguran{\c{c}}a da informa{\c{c}}{\~{a}}o,Tecnologia da Informa{\c{c}}{\~{a}}o.},
pages = {5--147},
title = {{Uma Abordagem Focada em Gest{\~{a}}o de Riscos}},
url = {http://www.marcusdantas.com.br/files/seguranca{\_}informacao.pdf},
year = {2011}
}
@article{Uto2009,
abstract = {Ruim de copiar, e necess{\'{a}}rio abrir o arquivo para ler},
author = {Uto, N and de Melo, SP},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/Capitulo{\_}6{\_}Vulnerabilidades{\_}em{\_}Aplicacoes{\_}Web{\_}e{\_}Me.pdf:pdf},
journal = {IX Simp{\'{o}}sio Brasileiro de Seguran{\c{c}}a da  {\ldots}},
number = {July},
pages = {237--283},
title = {{Vulnerabilidades em Aplica{\c{c}}oes Web e Mecanismos de Prote{\c{c}}ao}},
url = {http://www.lbd.dcc.ufmg.br:8080/colecoes/sbseg/2009/044.pdf},
year = {2009}
}
@article{Mello2006,
abstract = {Devido a sua caracter{\'{i}}stica integradora e por fazer uso de padr{\~{o}}es abertos, os Servi{\c{c}}os Web se tornaram uma {\'{a}}rea de grande interesse para pesquisa e para a ind{\'{u}}s- tria. Neste cap{\'{i}}tulo, pretende-se introduzir ao leitor os conceitos da arquitetura orientada a servi{\c{c}}os, e em particular, a sua mais atual caracteriza{\c{c}}{\~{a}}o, os Servi{\c{c}}os Web. Ser{\'{a}} mos- trado, atrav{\'{e}}s de um cen{\'{a}}rio de uso, os benef{\'{i}}cios em utilizar tal tecnologia e tamb{\'{e}}m ser{\~{a}}o apresentados os desafios de seguran{\c{c}}a associados a esta. Por fim, s{\~{a}}o apresen- tados alguns trabalhos de pesquisa e tecnologias voltadas para tratar tais desafios de seguran{\c{c}}a.},
author = {Mello, E.R. and Wangham, M.R. and Fraga, J.S.},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/mellomcsbseg06.pdf:pdf},
journal = {Minicursos do SBSeg 2006},
pages = {v. , p. 1--48},
title = {{Seguran{\c{c}}a em Servi{\c{c}}os Web}},
year = {2006}
}
@article{Peotta2006,
abstract = {RESUMO Um tema que vem sendo muito discutido {\'{e}} a governan{\c{c}}a em TI (Tecnologia da informa{\c{c}}{\~{a}}o), no entanto existem muitos m{\'{e}}todos e t{\'{e}}cnicas de gest{\~{a}}o que podem ser adotadas para se implement{\'{a}}-la. Um bom ponto de partida seria elaborar um plano para an{\'{a}}lise de risco em TI, controlando e conhecendo a infra-estrutura, agilizando a tomada de decis{\~{a}}o visando reduzir ou mitigar o risco. Neste artigo ser{\'{a}} descrito uma metodologia para efetuar uma an{\'{a}}lise de risco eficiente. Palavras-Chave: Gest{\~{a}}o de risco, Seguran{\c{c}}a da informa{\c{c}}{\~{a}}o, Governan{\c{c}}a, Compliance.},
author = {Peotta, Laerte and Gondim, Paulo},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/1049{\_}risco.pdf:pdf},
journal = {SEGeT – Simp{\'{o}}sio de Excel{\^{e}}ncia em Gest{\~{a}}o e Tecnologia},
pages = {1--12},
title = {{An{\'{a}}lise de Risco em Ambientes Corporativos na {\'{A}}rea de Tecnologia da Informa{\c{c}}{\~{a}}o}},
url = {http://ww.aedb.br/seget/artigos07/1049{\_}risco.pdf},
year = {2006}
}
@article{Miani2013,
author = {Miani, Rodrigo Sanches},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/Miani{\_}RodrigoSanches{\_}D.pdf:pdf},
title = {{Um estudo sobre m{\'{e}}tricas e quantifica{\c{c}}{\~{a}}o em seguran{\c{c}}a da informa{\c{c}}{\~{a}}o}},
year = {2013}
}
@article{Sabottke2015,
abstract = {In recent years, the number of software vulnerabilities discovered has grown significantly. This creates a need for prioritizing the response to new disclosures by assessing which vulnerabilities are likely to be exploited and by quickly ruling out the vulnerabilities that are not actually exploited in the real world. We conduct a quantitative and qualitative exploration of the vulnerability-related information disseminated on Twitter. We then describe the design of a Twitter-based exploit detector, and we introduce a threat model specific to our problem. In addition to response prioritization, our detection techniques have applications in risk modeling for cyber-insurance and they highlight the value of information provided by the victims of attacks.},
author = {Sabottke, Carl and Suciu, Octavian and Dumitraş, Tudor and Dumitras, Tudor},
doi = {10.2217/bmm.13.73},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/Vulnerability Disclosure in the Age of Social Media.pdf:pdf},
isbn = {9781931971232},
issn = {1752-0371},
journal = {USENIX Security Symposium},
pages = {1041--1056},
pmid = {24044570},
title = {{Vulnerability Disclosure in the Age of Social Media: Exploiting Twitter for Predicting Real-World Exploits}},
url = {https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/sabottke},
year = {2015}
}
@article{Correia2016,
author = {Correia, Andr{\'{e}} Marques},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/APRENDIZAGEM AUTOM{\'{A}}TICA EM LARGA ESCALA NAS.pdf:pdf},
title = {{Aprendizagem Autom{\'{a}}tica em Larga Escala nas Redes Sociais para a Descoberta de Amea{\c{c}}as de Seguran{\c{c}}a Mestrado Em Seguran{\c{c}}a Inform{\'{a}}tica}},
url = {http://hdl.handle.net/10451/24882},
year = {2016}
}
@article{ALVESBATISTA2007,
abstract = {A depend{\^{e}}ncia cada vez maior da tecnologia de informa{\c{c}}{\~{a}}o (TI) torna software seguro um elemento chave para a continuidade dos servi{\c{c}}os de nossa sociedade atual. Nos {\'{u}}ltimos anos, institui{\c{c}}{\~{o}}es p{\'{u}}blicas e privadas aumentaram seus investimentos em seguran{\c{c}}a da informa{\c{c}}{\~{a}}o, mas a quantidade de ataques vem crescendo mais rapidamente do que a nossa capacidade de poder enfrent{\'{a}}los, colocando em risco a propriedade intelectual, a rela{\c{c}}{\~{a}}o de confian{\c{c}}a de clientes e a opera{\c{c}}{\~{a}}o de servi{\c{c}}os e neg{\'{o}}cios apoiados pelos servi{\c{c}}os de TI. Especialistas em seguran{\c{c}}a afirmam que atualmente boa parte dos incidentes de seguran{\c{c}}a da informa{\c{c}}{\~{a}}o ocorrem a partir de vulnerabilidades encontradas no software, componente presente em boa parte dos sistemas de informa{\c{c}}{\~{a}}o. Para tornar o software fidedigno em rela{\c{c}}{\~{a}}o {\`{a}} seguran{\c{c}}a, a cria{\c{c}}{\~{a}}o e o uso de m{\'{e}}tricas de seguran{\c{c}}a ser{\~{a}}o fundamentais para gerenciar e entender o impacto dos programas de seguran{\c{c}}a nas empresas. Por{\'{e}}m, m{\'{e}}tricas de seguran{\c{c}}a s{\~{a}}o cobertas de mist{\'{e}}rio e consideradas bastante dif{\'{i}}ceis de serem implementadas. Este trabalho pretende mostrar que hoje ainda n{\~{a}}o {\'{e}} poss{\'{i}}vel termos m{\'{e}}tricas quantitativas capazes de indicar o n{\'{i}}vel de seguran{\c{c}}a que o software em desenvolvimento vir{\'{a}} a ter. Necessitam-se, ent{\~{a}}o, outras pr{\'{a}}ticas para assegurar n{\'{i}}veis de seguran{\c{c}}a a priori, ou seja, antes de se por o software em uso.},
author = {{ALVES BATISTA}, CARLOS FREUD},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/M{\'{e}}tricas de Seguran{\c{c}}a de Software.PDF:PDF},
title = {{M{\'{e}}tricas de Seguran{\c{c}}a de Software}},
year = {2007}
}
@article{Kroth2018,
author = {Kroth, Jonatha Augusto},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/ESTUDO E AN{\'{A}}LISE DE VULNERABILIDADES EM SERVI{\c{C}}OS.pdf:pdf},
pages = {0--74},
title = {{ESTUDO E AN{\'{A}}LISE DE VULNERABILIDADES EM SERVI{\c{C}}OS ESTUDO E AN{\'{A}}LISE DE VULNERABILIDADES EM SERVI{\c{C}}OS}},
year = {2018}
}
@misc{TheMITRECorporation2018,
author = {{The MITRE Corporation}},
file = {:C$\backslash$:/Users/rodri/OneDrive/{\'{A}}rea de Trabalho/CVE - Download CVE List.html:html},
title = {{CVE - Download CVE List}},
url = {https://cve.mitre.org/data/downloads/index.html},
urldate = {28/10/2019},
year = {2018}
}
@misc{Statista2019,
abstract = {As of the first quarter of 2019, Twitter averaged 330 million monthly active users, a decline from its all-time high of 336 MAU in the first quarter of 2018. As of the first quarter of 2019, the company switched its user reporting metric to monetizable daily active users (mDAU).},
author = {Statista},
booktitle = {Twitter: number of active users},
pages = {1},
title = {{Twitter: number of active users 2010-2019 | Statista}},
url = {https://www.statista.com/statistics/282087/number-of-monthly-active-twitter-users/},
urldate = {2019-10-30},
year = {2019}
}
@book{Pfleeger2015,
abstract = {469 p. il. 30 cm.},
author = {Pfleeger, Charlhes and Pfleeger, Shari and Margulies, Jonathan},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/security-in-computing-5-e-charles-p-pfleeger-pdf1.pdf:pdf},
isbn = {0975442201},
title = {{Security in Computing}},
year = {2015}
}
@misc{Pythoncommunity,
author = {Python community},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/GetOldTweets3 {\textperiodcentered} PyPI.html:html},
title = {{GetOldTweets3 {\textperiodcentered} PyPI}},
url = {https://pypi.org/project/GetOldTweets3/},
urldate = {2019-01-11}
}
@misc{JackDorseyNoahGlassBizStone2006,
abstract = {Twitter {\'{e}} uma rede social e um servidor para microblogging, que permite aos usu{\'{a}}rios enviar e receber atualiza{\c{c}}{\~{o}}es pessoais de outros contatos, por meio do website do servi{\c{c}}o, por SMS e por softwares espec{\'{i}}ficos de gerenciamento.},
author = {{Jack Dorsey, Noah Glass, Biz Stone}, Evan Williams},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/(20) Home {\_} Twitter.html:html},
title = {{Twitter}},
url = {https://twitter.com/home},
urldate = {2019-11-02},
year = {2006}
}
@misc{NISTDownload,
author = {NIST},
file = {:C$\backslash$:/Users/rodri/OneDrive/UFU/Gradua{\c{c}}{\~{a}}o em Sistemas de Informa{\c{c}}{\~{a}}o/8{\textordmasculine} Per{\'{i}}odo/TCC 2/NVD - Data Feeds.html:html},
title = {{NVD - Data Feeds}},
url = {https://nvd.nist.gov/vuln/data-feeds},
urldate = {09/11/2019}
}
